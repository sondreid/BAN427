{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Home Exam\r\n",
    "## BAN427: Insurance Analytics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import libraries:"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Modules\r\n",
    "import pandas as pd\r\n",
    "import os\r\n",
    "import numpy as np\r\n",
    "from scipy import stats\r\n",
    "import seaborn as sns\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.svm import SVC\r\n",
    "from sklearn.naive_bayes import GaussianNB\r\n",
    "from sklearn import model_selection, metrics\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "from matplotlib import pyplot\r\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Importing excel data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "master = pd.read_excel(\"exam_case_data.xlsx\")\r\n",
    "raw_df = master.copy()\r\n",
    "raw_df.head(10)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17764/3724933557.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmaster\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"exam_case_data.xlsx\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mraw_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adding columns for full churn, partial churn and more sale"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "# Adding new columns\r\n",
    "raw_df['FULL_CHURN']    = np.where(raw_df['TIME2'] != 2, 1, 0)\r\n",
    "raw_df['PARTIAL_CHURN'] = np.where((raw_df['NUMBER_COVERS_TIME2'] - raw_df['NUMBER_COVERS_TIME1']) < 0, 1, 0)\r\n",
    "raw_df['MORE_SALE']     = np.where((raw_df['NUMBER_COVERS_TIME2'] - raw_df['NUMBER_COVERS_TIME1']) > 0, 1, 0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\joonl\\AppData\\Local\\Temp/ipykernel_17780/3359999285.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['FULL_CHURN'][np.isnan(df['TIME2'])] = 1\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Descriptive statistics"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(df)\r\n",
    "df.FULL_CHURN.astype('category').describe()\r\n",
    "df.PARTIAL_CHURN.astype('category').describe()\r\n",
    "df.MORE_SALE.astype('category').describe()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "################ Clean data errors in tenure difference #############\r\n",
    "\r\n",
    "df = raw_df[(raw_df['TENURE_TIME2'] - raw_df['TENURE_TIME1'] == 0.5) | (raw_df['TIME2']).isnull()]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##  Churn and more sales by age groups. \r\n",
    "def age_groups(x):\r\n",
    "    \"\"\"'\r\n",
    "    Function that outputs  a string denoting an agegroup depending on\r\n",
    "    the input integer. \r\n",
    "    \"\"\"\r\n",
    "    if   x < 30:\r\n",
    "        return '<30'\r\n",
    "    elif x < 40:\r\n",
    "        return '<40'\r\n",
    "    elif x < 50:\r\n",
    "        return '<50'\r\n",
    "    elif x < 60:\r\n",
    "        return '<60'\r\n",
    "    elif x < 70:\r\n",
    "        return '<70'\r\n",
    "    else:\r\n",
    "        return '>=70'\r\n",
    "\r\n",
    "df['AGE_GROUP'] = df['AGE'].apply(age_groups)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Tables"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### Age table ##\r\n",
    "\r\n",
    "age_table = df.groupby(by=[\"AGE_GROUP\"]).describe().loc[:,['FULL_CHURN','PARTIAL_CHURN', \"MORE_SALE\"]]\r\n",
    "\r\n",
    "age_table.style\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Binary variables table\r\n",
    "\r\n",
    "format_table_dict = {'Percentage': '{:.2%}'}\r\n",
    "table_binary = pd.DataFrame([[(df.loc[df['FULL_CHURN'] == 1, 'FULL_CHURN']).count(), (df.loc[df['FULL_CHURN'] == 1, 'FULL_CHURN']).count()/len(df)],\r\n",
    "                     [(df.loc[df['PARTIAL_CHURN'] == 1, 'PARTIAL_CHURN']).count(), (df.loc[df['PARTIAL_CHURN'] == 1, 'PARTIAL_CHURN']).count()/len(df)],\r\n",
    "                     [(df.loc[df['MORE_SALE'] == 1, 'MORE_SALE']).count(), (df.loc[df['MORE_SALE'] == 1, 'MORE_SALE']).count()/len(df)]],\r\n",
    "                     index = ['Full churn (Positive)', 'Partial churn (Positive)', 'More sales (Positive)'],\r\n",
    "                     columns = [\"Count\", \"Percentage\"])\r\n",
    "\r\n",
    "table_binary.style.format(format_table_dict)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Number of covers table\r\n",
    "\r\n",
    "table_continous = pd.DataFrame({'Tenure time 1':(df['TENURE_TIME1']).describe()[1:,], 'Tenure time 2':(df['TENURE_TIME2']).describe()[1:,], \r\n",
    "                              'Number of Covers in period 1': (df['NUMBER_COVERS_TIME1']).describe()[1:,],\r\n",
    "                              'Number of Covers in period 2': (df['NUMBER_COVERS_TIME2']).describe()[1:,]})\r\n",
    "\r\n",
    "table_continous.style.format('{:.2f}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##  Churn and more sales by the size of portfolio. \r\n",
    "\r\n",
    "\r\n",
    "df['PREMIUM_INCREASE'] = np.where((df['TOTAL_PREM_TIME2'] - df['TOTAL_PREM_TIME1']) > 0, 1, 0)\r\n",
    "\r\n",
    "df.groupby(by=[\"PREMIUM_INCREASE\"]).describe().loc[:,['FULL_CHURN','PARTIAL_CHURN', \"MORE_SALE\"]]\r\n",
    "\r\n",
    "\r\n",
    "(df['TOTAL_PREM_TIME2'] - df['TOTAL_PREM_TIME1']).describe()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "##  Churn and more sales by whether customers has filed a claim\r\n",
    "df.groupby(by=['CLAIM_EVENT_BEFORE_TIME1']).describe().loc[:,['FULL_CHURN','PARTIAL_CHURN', \"MORE_SALE\"]]\r\n",
    "\r\n",
    "\r\n",
    "df.groupby(by=['AGE_GROUP', 'WOMAN']).describe().loc[:,['FULL_CHURN','PARTIAL_CHURN', \"MORE_SALE\"]]\r\n",
    "\r\n",
    "\r\n",
    "df.groupby(by=['WOMAN', 'AGE_GROUP']).describe().loc[:,['FULL_CHURN','PARTIAL_CHURN', \"MORE_SALE\"]]\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Significance tests"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## For all FULL CHURN MEN VS WOMEN\r\n",
    "\r\n",
    "age_woman = df.loc[df.WOMAN == 1, ['FULL_CHURN', 'PARTIAL_CHURN', 'MORE_SALE', 'AGE_GROUP']].groupby(by = 'AGE_GROUP').describe()\r\n",
    "age_men   = df.loc[df.WOMAN == 0, ['FULL_CHURN', 'PARTIAL_CHURN', 'MORE_SALE', 'AGE_GROUP']].groupby(by = 'AGE_GROUP').describe()\r\n",
    "\r\n",
    "stats.ttest_ind(age_woman[\"FULL_CHURN\"]['mean'], age_men[\"FULL_CHURN\"][\"mean\"], equal_var=False)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Plots"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sns.set_theme(palette='pastel')\r\n",
    "def bar_plot(df, x_var, hue_var, y_var, label_title, x_label, y_label, x_axis_label, y_axis_label):\r\n",
    "    \"\"\"\r\n",
    "    Generates a bar plot with hue.\r\n",
    "    \r\n",
    "    Parameters:\r\n",
    "        df: input dataframeÃ¸7609\r\n",
    "        x_var : x variable\r\n",
    "        hue_var: category variable. Is left out if empty string \"\". \r\n",
    "        y_var: y variable\r\n",
    "        label_title: Title of categories\r\n",
    "        x_label:\r\n",
    "\r\n",
    "    \"\"\" \r\n",
    "    if hue_var == \"\":\r\n",
    "        ax = sns.barplot(data = df,\r\n",
    "                x = x_var, \r\n",
    "                y = y_var)\r\n",
    "        ax.set_ylabel(y_axis_label)\r\n",
    "        ax.set_xlabel(x_axis_label)\r\n",
    "    else: \r\n",
    "        ax = sns.barplot(data = df,\r\n",
    "                    x = x_var, \r\n",
    "                    y = y_var, \r\n",
    "                    hue = hue_var)\r\n",
    "        ax.set_ylabel(y_axis_label)\r\n",
    "        ax.set_xlabel(x_axis_label)\r\n",
    "        labels = [x_label, y_label]\r\n",
    "        h, l = ax.get_legend_handles_labels()\r\n",
    "        ax.legend(h, labels, title = label_title)\r\n",
    "    return ax\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Line plot full churn by age group:\r\n",
    "df.FULL_CHURN.groupby(df.AGE_GROUP).count().plot()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FULL CHURNERS\r\n",
    "hist_df_full_churn_no_claim = df.loc[df.CLAIM_EVENT_BEFORE_TIME1 == 0,['FULL_CHURN','AGE_GROUP', 'WOMAN']].groupby(by = [\"AGE_GROUP\", 'WOMAN']).sum()\r\n",
    "hist_df_full_churn_no_claim.index.name = 'AGE_GROUP'\r\n",
    "hist_df_full_churn_no_claim.reset_index(inplace=True)\r\n",
    "\r\n",
    "bar_plot(hist_df_full_churn_no_claim, \"AGE_GROUP\", 'WOMAN', 'FULL_CHURN', 'GENDER', 'Men', 'Women', 'Claim Event', 'Number of full churners')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FULL CHURNERS given claim\r\n",
    "hist_df_full_churn_given_claim = df.loc[df.CLAIM_EVENT_BEFORE_TIME1 == 1,['FULL_CHURN','AGE_GROUP', 'WOMAN']].groupby(by = [\"AGE_GROUP\", 'WOMAN']).sum()\r\n",
    "hist_df_full_churn_given_claim.index.name = 'AGE_GROUP'\r\n",
    "hist_df_full_churn_given_claim.reset_index(inplace=True)\r\n",
    "\r\n",
    "bar_plot(hist_df_full_churn_given_claim, \"AGE_GROUP\", 'WOMAN', 'FULL_CHURN', 'GENDER', 'Men', 'Women', 'Claim Event', 'Number of full churners given filed claim' )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# FULL CHURN by claim event \r\n",
    "hist_df_full_claim_event = df.loc[:,['FULL_CHURN','CLAIM_EVENT_BEFORE_TIME1', 'WOMAN']].groupby(by = ['CLAIM_EVENT_BEFORE_TIME1', 'WOMAN']).mean()\r\n",
    "hist_df_full_claim_event.index.name = 'CLAIM_EVENT_BEFORE_TIME1'\r\n",
    "hist_df_full_claim_event.reset_index(inplace=True)\r\n",
    "\r\n",
    "bar_plot(hist_df_full_claim_event, \"CLAIM_EVENT_BEFORE_TIME1\", 'WOMAN', 'FULL_CHURN', 'GENDER', 'Men', 'Women', 'Claim Event', 'Number of full churners' )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# PARTIAL CHURNERS\r\n",
    "hist_df_partial_churn = df.loc[:,['PARTIAL_CHURN','AGE_GROUP', 'WOMAN']].groupby(by = [\"AGE_GROUP\", 'WOMAN']).sum()\r\n",
    "hist_df_partial_churn.index.name = 'AGE_GROUP'\r\n",
    "hist_df_partial_churn.reset_index(inplace=True)\r\n",
    "\r\n",
    "# Partial plot\r\n",
    "bar_plot(hist_df_partial_churn, \"AGE_GROUP\", 'WOMAN', 'PARTIAL_CHURN', 'GENDER', 'Men', 'Women', 'Age Group', 'Number of partial churners' )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MORE SALE\r\n",
    "hist_df_more_sale = df.loc[:,['MORE_SALE','AGE_GROUP', 'WOMAN']].groupby(by = [\"AGE_GROUP\", 'WOMAN']).sum()\r\n",
    "hist_df_more_sale.index.name = 'AGE_GROUP'\r\n",
    "hist_df_more_sale.reset_index(inplace=True)\r\n",
    "\r\n",
    "# More sales plot\r\n",
    "bar_plot(hist_df_more_sale, \"AGE_GROUP\", 'WOMAN', 'MORE_SALE', 'GENDER', 'Men', 'Women', 'Age Group', 'Number of increase in coverage' )\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# MORE SALE\r\n",
    "hist_df_more_sale = df.loc[:,['MORE_SALE','AGE_GROUP', 'WOMAN']].groupby(by = [\"AGE_GROUP\", 'WOMAN']).sum()\r\n",
    "hist_df_more_sale.index.name = 'AGE_GROUP'\r\n",
    "hist_df_more_sale.reset_index(inplace=True)\r\n",
    "\r\n",
    "# More sales plot\r\n",
    "bar_plot(hist_df_more_sale, \"AGE_GROUP\", 'WOMAN', 'MORE_SALE', 'GENDER', 'Men', 'Women', 'Age Group', 'Number of increase in coverage' )\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prediction Models"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Creating features and prediction variables\r\n",
    "\r\n",
    "x = df.loc[:, ~df.columns.isin(['TIME1', 'NUMBER_COVERS_TIME2', 'PREMIUM_INCREASE', 'TIME2', 'TOTAL_PREM_TIME2', 'AVERAGE_INCOME_COUNTY_TIME1','TENURE_TIME2','FULL_CHURN', 'PARTIAL_CHURN', 'MORE_SALE'])]\r\n",
    "\r\n",
    "\r\n",
    "## One hot encoding age group feature\r\n",
    "one_hot_encoder = OneHotEncoder(handle_unknown= 'ignore')\r\n",
    "\r\n",
    "one_hot_encoder.fit(df[['AGE_GROUP']])\r\n",
    "\r\n",
    "age_group_hot = one_hot_encoder.transform(df[['AGE_GROUP']]).toarray()\r\n",
    "age_group_hot\r\n",
    "\r\n",
    "age_group_hot_df = pd.DataFrame(age_group_hot)\r\n",
    "age_group_hot_df.columns = one_hot_encoder.get_feature_names()\r\n",
    "\r\n",
    "# Concat into x\r\n",
    "x = pd.concat([x.reset_index(drop=True), age_group_hot_df], axis=1)\r\n",
    "x = x.loc[:, x.columns != 'AGE_GROUP'] # Remove string AGE_GROUP\r\n",
    "\r\n",
    "# Check for NaN\r\n",
    "x[x.isna().any(axis=1)]\r\n",
    "\r\n",
    "\r\n",
    "y_full_churn    = df['FULL_CHURN']\r\n",
    "y_partial_churn = df['PARTIAL_CHURN']\r\n",
    "y_more_sale     = df['MORE_SALE']\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Splitting the data into train and test [fc = full churn, pc = partial churn, ms = more sales]\r\n",
    "\r\n",
    "xtrain_fc, xtest_fc, ytrain_fc, ytest_fc = train_test_split(x, y_full_churn,    test_size = 0.2, random_state = 0)\r\n",
    "xtrain_pc, xtest_pc, ytrain_pc, ytest_pc = train_test_split(x, y_partial_churn, test_size = 0.2, random_state = 0)\r\n",
    "xtrain_ms, xtest_ms, ytrain_ms, ytest_ms = train_test_split(x, y_more_sale,     test_size = 0.2, random_state = 0)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Scaling the features\r\n",
    "\r\n",
    "sc = StandardScaler()\r\n",
    "\r\n",
    "xtrain_fc = sc.fit_transform(xtrain_fc)\r\n",
    "xtest_fc  = sc.transform(xtest_fc)\r\n",
    "\r\n",
    "xtrain_pc = sc.fit_transform(xtrain_pc)\r\n",
    "xtest_pc  = sc.transform(xtest_pc)\r\n",
    "\r\n",
    "xtrain_ms = sc.fit_transform(xtrain_ms)\r\n",
    "xtest_ms  = sc.transform(xtest_ms)\r\n",
    "\r\n",
    "\r\n",
    "# Check for Nan\r\n",
    "np.any(np.isnan(xtrain_fc))\r\n",
    "np.any(np.isfinite(xtrain_fc))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########################## Training the logistic regression model\r\n",
    "\r\n",
    "\r\n",
    "logreg_fc = LogisticRegression(random_state = 0)\r\n",
    "logreg_fc.fit(xtrain_fc, ytrain_fc)\r\n",
    "\r\n",
    "logreg_pc = LogisticRegression(random_state = 0)\r\n",
    "logreg_pc.fit(xtrain_pc, ytrain_pc)\r\n",
    "\r\n",
    "logreg_ms = LogisticRegression(random_state = 0)\r\n",
    "logreg_ms.fit(xtrain_ms, ytrain_ms)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Predicting the logreg model\r\n",
    "ypred_logreg_fc = logreg_fc.predict(xtest_fc)\r\n",
    "yprob_logreg_fc = (logreg_fc.predict_proba(xtest_fc)[:,1]  >= 0.05).astype(bool)\r\n",
    "\r\n",
    "ypred_logreg_pc = logreg_pc.predict(xtest_pc)\r\n",
    "yprob_logreg_pc = (logreg_pc.predict_proba(xtest_pc)[:,1]  >= 0.05).astype(bool)\r\n",
    "\r\n",
    "ypred_logreg_ms = logreg_ms.predict(xtest_ms)\r\n",
    "yprob_logreg_ms = (logreg_pc.predict_proba(xtest_ms)[:,1]  >= 0.05).astype(bool)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def variable_importance(model):\r\n",
    "    \"\"\"\"\r\n",
    "    Function that takes a fitted model and enumerates its features' importance.\r\n",
    "    Prints a barplot\r\n",
    "    parameters:\r\n",
    "        @model: fitted model\r\n",
    "    \"\"\"\r\n",
    "    importance = model.coef_[0]\r\n",
    "    for i,v in enumerate(importance):\r\n",
    "            print('Feature: %0d, Score: %.5f' % (i,v))\r\n",
    "    \r\n",
    "    pyplot.bar([x for x in range(len(importance))], importance)\r\n",
    "    pyplot.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Variable importance  \r\n",
    "#FC \r\n",
    "variable_importance(logreg_fc)\r\n",
    "\r\n",
    "# Confusion matrix\r\n",
    "cm_fc = confusion_matrix(ytest_fc, ypred_logreg_fc)\r\n",
    "print(cm_fc)\r\n",
    "accuracy_score(ytest_fc, ypred_logreg_fc)\r\n",
    "\r\n",
    "cm_pc = confusion_matrix(ytest_pc, ypred_logreg_pc)\r\n",
    "print(cm_pc)\r\n",
    "accuracy_score(ytest_pc, ypred_logreg_pc)\r\n",
    "\r\n",
    "cm_ms = confusion_matrix(ytest_ms, ypred_logreg_ms)\r\n",
    "print(cm_ms)\r\n",
    "accuracy_score(ytest_ms, ypred_logreg_ms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#ROC-curve function\r\n",
    "def roc(ytrain, x_train, ytest, x_test, model):\r\n",
    "    \"\"\"\r\n",
    "    Function that draws a ROC curve based o\r\n",
    "    Parameters:\r\n",
    "        @ytrain: target feature training set\r\n",
    "        @x_train: features training set\r\n",
    "        @y_test: target feature test set\r\n",
    "        @x_test: features test set\r\n",
    "        @model: a fitted model\r\n",
    "    \"\"\"\r\n",
    "    fit_proba = model.predict_proba(x_train)\r\n",
    "    yprob_pred = model.predict_proba(x_test)\r\n",
    "\r\n",
    "    fpr, tpr, tr = metrics.roc_curve(ytest, yprob_pred[:,1])\r\n",
    "    auc = metrics.roc_auc_score(ytest, yprob_pred[:, 1])\r\n",
    "\r\n",
    "    fpr1, tpr1, tr = metrics.roc_curve(ytrain, fit_proba[:,1])\r\n",
    "    auc1 = metrics.roc_auc_score(ytrain, fit_proba[:,1])\r\n",
    "\r\n",
    "    plt.figure(num = None, figsize = (10,10), dpi = 80)\r\n",
    "\r\n",
    "    plt.plot((1,0), (1,0), ls = \"--\", c = \".3\")\r\n",
    "    plt.title = (' ROC Curve - test and train data')\r\n",
    "    plt.xlabel('False positive rate')\r\n",
    "    plt.plot(fpr, tpr, label = '{} test data (area = {:.2f})'.format(model, auc))\r\n",
    "    plt.plot(fpr1, tpr1, label = '{} train data (area = {:.2f})'.format(model, auc1))\r\n",
    "    plt.ylabel('True positive rate')\r\n",
    "    plt.legend()\r\n",
    "    plt.show()\r\n",
    "    return plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ROC curve logreg\r\n",
    "\r\n",
    "roc_logreg_fc = roc(ytrain_fc, ytest_fc, yprob_logreg_fc)\r\n",
    "roc_logreg_fc\r\n",
    "\r\n",
    "roc_logreg_pc = roc(ytrain_pc, ytest_pc, yprob_logreg_pc)\r\n",
    "roc_logreg_pc\r\n",
    "\r\n",
    "roc_logreg_ms = roc(ytrain_ms, ytest_ms, yprob_logreg_ms)\r\n",
    "roc_logreg_ms\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########################## Training the KNN-model\r\n",
    "from sklearn.neighbors import KNeighborsClassifier\r\n",
    "\r\n",
    "knn_fc = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\r\n",
    "knn_fc.fit(xtrain_fc, ytrain_fc)\r\n",
    "\r\n",
    "knn_pc = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\r\n",
    "knn_pc.fit(xtrain_pc, ytrain_pc)\r\n",
    "\r\n",
    "knn_ms = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\r\n",
    "knn_ms.fit(xtrain_ms, ytrain_ms)\r\n",
    "\r\n",
    "# Predicting the knn models\r\n",
    "ypred_knn_fc = knn_fc.predict(xtest_fc)\r\n",
    "\r\n",
    "ypred_knn_pc = knn_pc.predict(xtest_pc)\r\n",
    "\r\n",
    "ypred_knn_ms = knn_ms.predict(xtest_ms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking the accuracy with confusion matrix\r\n",
    "cm_knn_fc = confusion_matrix(ytest_fc, ypred_knn_fc)\r\n",
    "print(cm_knn_fc)\r\n",
    "accuracy_score(ytest_fc, ypred_knn_fc)\r\n",
    "\r\n",
    "\r\n",
    "tn, fp, fn, tp = confusion_matrix(ytest_fc, ypred_knn_fc).ravel()\r\n",
    "(tn, fp, fn, tp)\r\n",
    "\r\n",
    "\r\n",
    "cm_knn_pc = confusion_matrix(ytest_pc, ypred_knn_pc)\r\n",
    "print(cm_knn_pc)\r\n",
    "accuracy_score(ytest_pc, ypred_knn_pc)\r\n",
    "\r\n",
    "\r\n",
    "cm_knn_ms = confusion_matrix(ytest_ms, ypred_knn_ms)\r\n",
    "print(cm_knn_ms)\r\n",
    "accuracy_score(ytest_ms, ypred_knn_ms)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "### ROC-curve KNN ###\r\n",
    "\r\n",
    "roc_KNN_fc = roc(ytrain_fc, xtrain_fc, ytest_fc, xtest_fc, knn_fc)\r\n",
    "roc_KNN_fc"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "########################## Training the SVM-model\r\n",
    "\r\n",
    "\r\n",
    "svc_fc = SVC(kernel = 'linear', random_state = 0, probability = True)\r\n",
    "svc_fc.fit(xtrain_fc, ytrain_fc)\r\n",
    "\r\n",
    "svc_pc = SVC(kernel = 'linear', random_state = 0, probability = True)\r\n",
    "svc_pc.fit(xtrain_pc, ytrain_pc)\r\n",
    "\r\n",
    "svc_ms = SVC(kernel = 'linear', random_state = 0, probability = True)\r\n",
    "svc_ms.fit(xtrain_ms, ytrain_ms)\r\n",
    "\r\n",
    "# Predicting the svm model\r\n",
    "ypred_svc_fc = (svc_fc.predict_proba(xtest_fc)[:,1]  >= 0.05).astype(bool)\r\n",
    "ypred_svc_pc = (svc_pc.predict_proba(xtest_pc)[:,1]  >= 0.05).astype(bool)\r\n",
    "ypred_svc_ms = (svc_ms.predict_proba(xtest_ms)[:,1]  >= 0.05).astype(bool)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Checking the accuracy with confusion matrix\r\n",
    "cm_svc_fc = confusion_matrix(ytest_fc, ypred_svc_fc)\r\n",
    "print(cm_svc_fc)\r\n",
    "accuracy_score(ytest_fc, ypred_svc_fc)\r\n",
    "\r\n",
    "cm_svc_pc = confusion_matrix(ytest_pc, ypred_svc_pc)\r\n",
    "print(cm_svc_pc)\r\n",
    "accuracy_score(ytest_pc, ypred_svc_pc)\r\n",
    "\r\n",
    "cm_svc_ms = confusion_matrix(ytest_ms, ypred_svc_ms)\r\n",
    "print(cm_svc_ms)\r\n",
    "accuracy_score(ytest_ms, ypred_svc_ms)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#ROC Curve SVM\r\n",
    "roc_SVM_fc = roc(ytrain_fc, xtrain_fc, ytest_fc, xtest_fc, svc_fc)\r\n",
    "roc_SVM_fc\r\n",
    "\r\n",
    "roc_SVM_pc = roc(ytrain_pc, ytest_pc, ypred_svc_pc)\r\n",
    "roc_SVM_pc\r\n",
    "\r\n",
    "roc_SVM_ms = roc(ytrain_ms, ytest_ms, ypred_svc_ms)\r\n",
    "roc_SVM_ms\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "####### SVM-model with 'AVERAGE_INCOME_COUNTY_TIME1' ######\r\n",
    "\r\n",
    "df_avg_income = df[df['AVERAGE_INCOME_COUNTY_TIME1'].notna()]\r\n",
    "\r\n",
    "y_full_churn_avg_income   = df_avg_income['FULL_CHURN']\r\n",
    "xtrain_avg_income, xtest_avg_income, ytrain_avg_income, ytest_avg_income = train_test_split(x_avg_income, y_full_churn_avg_income, test_size = 0.2, random_state = 0)\r\n",
    "\r\n",
    "svc_fc = SVC(kernel = 'linear', random_state = 0, probability = True)\r\n",
    "svc_fc.fit(xtrain_avg_income, ytrain_avg_income)\r\n",
    "\r\n",
    "# Predicting the svm model\r\n",
    "ypred_svc_avg_income = (svc_fc.predict_proba(xtest_avg_income)[:,1]  >= 0.05).astype(bool)\r\n",
    "\r\n",
    "# Checking the accuracy with confusion matrix\r\n",
    "cm_svc_avg_income = confusion_matrix(ytest_avg_income, ypred_svc_avg_income)\r\n",
    "print(cm_svc_avg_income)\r\n",
    "accuracy_score(ytest_avg_income, ypred_svc_avg_income)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#Training the Naive bayes-model\r\n",
    "\r\n",
    "nb_fc = GaussianNB\r\n",
    "nb_fc.fit(xtrain_fc, ytrain_fc)\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Traning the Random Forest\r\n",
    "rfc_fc = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\r\n",
    "rfc_fc = rfc_fc.fit(xtrain_fc, ytrain_fc)\r\n",
    "\r\n",
    "# Prediction\r\n",
    "ypred_rfc_fc = (rfc_fc.predict_proba(xtest_fc)[:,1] > 0.2).astype(bool)\r\n",
    "\r\n",
    "# Accuracy\r\n",
    "cm_rfc_fc = confusion_matrix(ytest_fc, ypred_rfc_fc)\r\n",
    "print(cm_rfc_fc)\r\n",
    "recall_score(ytest_fc, ypred_rfc_fc)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def test_treshold(model, n, x_test, y_test):\r\n",
    "    \"\"\" \r\n",
    "    parameters:\r\n",
    "        @model: fitted model\r\n",
    "    \"\"\"  \r\n",
    "    best_score = 0\r\n",
    "    best_treshold = 0\r\n",
    "    for i in range(n):\r\n",
    "        print(i/n)\r\n",
    "        treshold = i/n \r\n",
    "        print(best_score)\r\n",
    "        y_preds = (model.predict_proba(x_test)[:,1] >= treshold).astype(bool)\r\n",
    "        accuracy_test = recall_score(y_test, y_preds)\r\n",
    "        if accuracy_test > best_score:\r\n",
    "            best_score = accuracy_test\r\n",
    "            best_treshold = treshold\r\n",
    "\r\n",
    "    return best_treshold, best_score\r\n",
    "test_treshold(rfc_fc, 100, xtest_fc, ytest_fc)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.4",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit"
  },
  "interpreter": {
   "hash": "a3f5497e1d0146471da1d4faeb6ed2053ec42dffb4905bb9b80a6982efd96613"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}